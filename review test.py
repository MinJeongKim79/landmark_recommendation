from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import pandas as pd
import time
import random
from selenium.common.exceptions import NoSuchElementException
import pickle


def init_driver():
    options = ChromeOptions()
    # ì‚¬ìš©ì ì—ì´ì „íŠ¸ ì„¤ì • (ì‚¬ëŒì²˜ëŸ¼ ë³´ì´ë„ë¡ ìœ„ì¥)
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    options.add_argument("--disable-blink-features=AutomationControlled")
    # options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ìˆ¨ê¹€ ì‹¤í–‰ ì‹œ í•„ìš”

    service = ChromeService(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # navigator.webdriver ê°ì¶”ê¸° (íƒì§€ íšŒí”¼)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
            Object.defineProperty(navigator, 'webdriver', {
              get: () => undefined
            })
        """
    })

    return driver

def is_detail_page(driver):
    # ìƒì„¸ í˜ì´ì§€ì¸ì§€ íŒë‹¨í•˜ëŠ” í•µì‹¬ ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
    try:
        driver.find_element(By.XPATH, "/html/body/div[1]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[2]")
        return True
    except NoSuchElementException:
        return False

def is_list_page(driver):
    # ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì¸ì§€ íŒë‹¨
    try:
        driver.find_element(By.CLASS_NAME, "Nv2PK")  # ê²€ìƒ‰ê²°ê³¼ ì¹´ë“œ ì¡´ì¬ ì—¬ë¶€
        return True
    except NoSuchElementException:
        return False

def click_first_result(driver):
    # ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ê²°ê³¼ í´ë¦­
    try:
        first_result = driver.find_elements(By.CLASS_NAME, "Nv2PK")[0]
        first_result.click()
        time.sleep(2)
        return True
    except Exception as e:
        print(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ í´ë¦­ ì‹¤íŒ¨: {e}")
        return False

def search_place(driver, place_name):
    # í†µí•©ëœ ê²€ìƒ‰ ë° íŒë‹¨ ë¡œì§
    driver.get("https://www.google.com/maps")
    time.sleep(1.5)

    search_box = driver.find_element(By.ID, "searchboxinput")
    search_box.clear()
    search_box.send_keys(place_name)
    search_box.send_keys(Keys.ENTER)
    print(f"ğŸ” '{place_name}' ê²€ìƒ‰ ì¤‘...")
    time.sleep(3)

    if is_detail_page(driver):
        print(f"âœ… '{place_name}' â†’ ë°”ë¡œ ìƒì„¸ í˜ì´ì§€ ì§„ì…")
        return True

    elif is_list_page(driver):
        print(f"ğŸ“‹ '{place_name}' â†’ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ í‘œì‹œë¨")
        if click_first_result(driver):
            if is_detail_page(driver):
                print(f"âœ… '{place_name}' â†’ ë¦¬ìŠ¤íŠ¸ì—ì„œ ìƒì„¸ í˜ì´ì§€ ì§„ì… ì„±ê³µ")
                return True
            else:
                print(f"âš ï¸ '{place_name}' â†’ í´ë¦­ í›„ì—ë„ ìƒì„¸ í˜ì´ì§€ ì¸ì‹ ì‹¤íŒ¨")
                return False
        else:
            print(f"âŒ '{place_name}' â†’ ì²« ê²°ê³¼ í´ë¦­ ì‹¤íŒ¨")
            return False

    else:
        print(f"â“ '{place_name}' â†’ ìƒì„¸ë„ ë¦¬ìŠ¤íŠ¸ë„ ì•„ë‹˜")
        return False

def click_review_tab(driver):
    try:
        xpath_list = [
            "/html/body/div[1]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[2]",
            "/html/body/div[1]/div[3]/div[8]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[3]"
        ]

        for xpath in xpath_list:
            try:
                button = driver.find_element(By.XPATH, xpath)
                if "ë¦¬ë·°" in button.text:
                    button.click()
                    print(f"ğŸ“ ë¦¬ë·° íƒ­ í´ë¦­ ì„±ê³µ: {xpath}")
                    time.sleep(2)
                    return True
            except NoSuchElementException:
                continue

        print("âŒ ë¦¬ë·° íƒ­ ë²„íŠ¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ 'ë¦¬ë·°' íƒ­ì´ ì•„ë‹˜")
        return False

    except Exception as e:
        print(f"ğŸš¨ ë¦¬ë·° íƒ­ í´ë¦­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def scroll_review_section(driver, max_reviews=50):
    # ìŠ¤í¬ë¡¤ ë‹¤ìš´ì„ í†µí•´ ë¦¬ë·° ë¡œë“œí•˜ê¸°
    scrollable_div = driver.find_element(By.CSS_SELECTOR, 'div.m6QErb.DxyBCb.kA9KIf.dS8AEf')

    for _ in range(20):
        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)
        time.sleep(0.2)

    print(f"ğŸ“œ ë¦¬ë·° ìŠ¤í¬ë¡¤ ì¢…ë£Œ")

def extract_reviews(driver, max_reviews=50):
    # ë°ì´í„° ìˆ˜ì§‘
    # review_elements = driver.find_elements(By.CLASS_NAME, 'wiI7pd')
    try:
        review_elements = driver.find_elements(By.CLASS_NAME, 'wiI7pd')[:max_reviews]
        rating_elements = driver.find_elements(By.CLASS_NAME, 'kvMYJc')[:max_reviews]
        reviews = [element.text for element in review_elements]
        ratings = [element.get_attribute('aria-label') if element.get_attribute('aria-label') else None for element in rating_elements]
        time.sleep(2)
        print(reviews)
        print(ratings)
        return reviews, ratings
    except Exception as e:
        print(f"ğŸš¨ ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [], []

def collect_reviews_for_place(driver, max_reviews):
    if not click_review_tab(driver):
        return [], []
    time.sleep(4) # ë¦¬ë·° ì˜ì—­ ë Œë”ë§ ëŒ€ê¸°
    scroll_review_section(driver, max_reviews=max_reviews)
    return extract_reviews(driver, max_reviews=max_reviews)


def main():
    # CSVì—ì„œ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì§€ì—­ë§ˆë‹¤ ì´ë¦„ì„ ë³€ê²½í•´ì•¼ í•¨)
    df = pd.read_csv("./dataset/KMJ/name_list_for_search/Daejeon_names_list.csv")
    place_names = df["name"].tolist()
    print(place_names)

    driver = init_driver()
    all_reviews = []
    all_ratings = []

    for i, place in enumerate(place_names):
        print(f"\n[{i + 1}/{len(place_names)}] '{place}' ê²€ìƒ‰ ì¤‘...")
        success = search_place(driver, place)
        time.sleep(random.uniform(1.5, 2.5))

        if success:
            reviews, ratings = collect_reviews_for_place(driver, max_reviews=50)  # âœ… ì—¬ê¸°!
            concat_reviews = ' '.join(reviews)
            all_reviews.append(concat_reviews)
            concat_ratings = ' '.join(ratings)
            all_ratings.append(concat_ratings)

        else :
            all_reviews.append("?")
            all_ratings.append("?")

        if i % 20 == 0 and i != 0:
            print("â™»ï¸ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì¤‘...")
            driver.quit()
            driver = init_driver()

    driver.quit()
    print(len(all_reviews))
    print(len(all_ratings))
    with open('./dataset/Daejeon_reviews.pickle', 'wb') as f:
        pickle.dump(all_reviews, f)
    with open('./dataset/Daejeon_ratings.pickle', 'wb') as f:
        pickle.dump(all_ratings, f)



    df_out = pd.DataFrame({'names':place_names, 'reviews':all_reviews, 'rating': all_ratings})
    df_out.to_csv("./dataset/LES/google_maps_reviews/Daejeon_reviews.csv", index=False, encoding='utf-8-sig')
    print("âœ… ë¦¬ë·° ì €ì¥ ì™„ë£Œ: Daejeon_reviews.csv")

if __name__ == "__main__":
    main()